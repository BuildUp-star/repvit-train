{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26c9bbbe-4866-4dc1-a0de-9ecd74aaca6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/bin/env python3\n",
    "# -*- coding: utf-8 -*-\n",
    "\n",
    "import os, csv, argparse, random, time\n",
    "from typing import List, Tuple\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms\n",
    "\n",
    "import timm  # 需要: pip install timm\n",
    "\n",
    "# ----------------- utils -----------------\n",
    "def set_seed(seed=42):\n",
    "    random.seed(seed); np.random.seed(seed)\n",
    "    torch.manual_seed(seed); torch.cuda.manual_seed_all(seed)\n",
    "\n",
    "def normalize(z): return F.normalize(z, dim=-1)\n",
    "\n",
    "# ----------------- datasets -----------------\n",
    "class PairDataset(Dataset):\n",
    "    def __init__(self, pos_csv, neg_csv, transform):\n",
    "        self.samples = []\n",
    "        if os.path.exists(pos_csv):\n",
    "            with open(pos_csv, 'r', encoding='utf-8') as f:\n",
    "                for r in csv.DictReader(f):\n",
    "                    self.samples.append((r['a'], r['b'], 1.0))\n",
    "        if os.path.exists(neg_csv):\n",
    "            with open(neg_csv, 'r', encoding='utf-8') as f:\n",
    "                for r in csv.DictReader(f):\n",
    "                    self.samples.append((r['a'], r['b'], 0.0))\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self): return len(self.samples)\n",
    "    def __getitem__(self, i):\n",
    "        a, b, y = self.samples[i]\n",
    "        ia = Image.open(a).convert(\"RGB\")\n",
    "        ib = Image.open(b).convert(\"RGB\")\n",
    "        return self.transform(ia), self.transform(ib), torch.tensor(y, dtype=torch.float32)\n",
    "\n",
    "class TripletDataset(Dataset):\n",
    "    def __init__(self, csv_path, transform):\n",
    "        with open(csv_path, 'r', encoding='utf-8') as f:\n",
    "            self.rows = [(r['anchor'], r['positive'], r['negative']) for r in csv.DictReader(f)]\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self): return len(self.rows)\n",
    "    def __getitem__(self, i):\n",
    "        a, p, n = self.rows[i]\n",
    "        ia = Image.open(a).convert(\"RGB\")\n",
    "        ip = Image.open(p).convert(\"RGB\")\n",
    "        ineg = Image.open(n).convert(\"RGB\")\n",
    "        return self.transform(ia), self.transform(ip), self.transform(ineg)\n",
    "\n",
    "# ----------------- model wrap -----------------\n",
    "class RepViTWithHead(nn.Module):\n",
    "    \"\"\" 复用已创建的 timm 模型，移除分类头，接 512-d embedding head \"\"\"\n",
    "    def __init__(self, backbone: nn.Module, embed_dim=512, mlp=False):\n",
    "        super().__init__()\n",
    "        self.backbone = backbone\n",
    "\n",
    "        # 移除分类头 + 启用全局池化，确保 forward 输出为 (B, feat_dim)\n",
    "        if hasattr(self.backbone, 'reset_classifier'):\n",
    "            self.backbone.reset_classifier(num_classes=0, global_pool='avg')\n",
    "        feat_dim = getattr(self.backbone, 'num_features', None)\n",
    "        if feat_dim is None:\n",
    "            # 兜底：跑一次 dummy 推理推断维度\n",
    "            with torch.no_grad():\n",
    "                z = self.backbone(torch.zeros(1,3,224,224))\n",
    "                feat_dim = z.shape[-1]\n",
    "\n",
    "        if mlp:\n",
    "            self.head = nn.Sequential(\n",
    "                nn.Linear(feat_dim, feat_dim),\n",
    "                nn.ReLU(inplace=True),\n",
    "                nn.Linear(feat_dim, embed_dim),\n",
    "            )\n",
    "        else:\n",
    "            self.head = nn.Linear(feat_dim, embed_dim)\n",
    "\n",
    "    def forward(self, x):\n",
    "        f = self.backbone(x)          # (B, feat_dim)，已全局池化\n",
    "        z = self.head(f)              # (B, embed_dim)\n",
    "        return normalize(z)           # 归一化，便于余弦相似\n",
    "\n",
    "def freeze_by_ratio(module: nn.Module, ratio: float):\n",
    "    \"\"\"按参数次序冻结前 ratio 比例（0~1）。不依赖具体层名，通用且稳妥。\"\"\"\n",
    "    params = [p for p in module.parameters()]\n",
    "    cutoff = int(len(params) * ratio)\n",
    "    for i, p in enumerate(params):\n",
    "        p.requires_grad = (i >= cutoff)\n",
    "\n",
    "# ----------------- losses -----------------\n",
    "class BCEPairLoss(nn.Module):\n",
    "    def __init__(self, scale=20.0):\n",
    "        super().__init__()\n",
    "        self.scale = scale\n",
    "        self.crit = nn.BCEWithLogitsLoss()\n",
    "    def forward(self, za, zb, y):\n",
    "        logit = (za * zb).sum(-1) * self.scale\n",
    "        return self.crit(logit, y)\n",
    "\n",
    "# ----------------- eval: 组内最近邻召回 -----------------\n",
    "def read_items(csv_path):\n",
    "    rows = []\n",
    "    with open(csv_path, 'r', encoding='utf-8') as f:\n",
    "        for r in csv.DictReader(f):\n",
    "            rows.append((r['path'], f\"{r['class']}/{r['group']}\"))\n",
    "    return rows\n",
    "\n",
    "@torch.no_grad()\n",
    "def eval_group_recall(model, test_csv, image_size, device):\n",
    "    if not os.path.exists(test_csv): return None\n",
    "    rows = read_items(test_csv)\n",
    "    tfm = transforms.Compose([\n",
    "        transforms.Resize(image_size),\n",
    "        transforms.CenterCrop(image_size),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize((0.485,0.456,0.406),(0.229,0.224,0.225)),\n",
    "    ])\n",
    "    embs, groups = [], []\n",
    "    model.eval()\n",
    "    for path, gid in rows:\n",
    "        x = tfm(Image.open(path).convert('RGB')).unsqueeze(0).to(device)\n",
    "        z = model(x).cpu().numpy()[0]\n",
    "        embs.append(z); groups.append(gid)\n",
    "    embs = np.stack(embs, 0)\n",
    "    embs = embs / (np.linalg.norm(embs, axis=1, keepdims=True)+1e-9)\n",
    "    sims = embs @ embs.T\n",
    "    np.fill_diagonal(sims, -1.0)\n",
    "    nn_idx = sims.argmax(1)\n",
    "    hits = sum(1 for i,j in enumerate(nn_idx) if groups[i]==groups[j])\n",
    "    return hits/len(rows)\n",
    "\n",
    "# ----------------- train -----------------\n",
    "def main():\n",
    "    ap = argparse.ArgumentParser()\n",
    "    ap.add_argument('--csv_dir', type=str, default='dataset/00train_test')\n",
    "    ap.add_argument('--method', type=str, choices=['triplet','pairs-bce'], default='triplet')\n",
    "    ap.add_argument('--model_name', type=str, default='repvit_m1_0')\n",
    "    ap.add_argument('--embed_dim', type=int, default=512)\n",
    "    ap.add_argument('--freeze_ratio', type=float, default=0.8, help='冻结前多少比例参数 (0~1)')\n",
    "    ap.add_argument('--mlp_head', action='store_true', help='使用两层 MLP 作为 head')\n",
    "    ap.add_argument('--image_size', type=int, default=224)\n",
    "    ap.add_argument('--batch_size', type=int, default=64)\n",
    "    ap.add_argument('--epochs', type=int, default=10)\n",
    "    ap.add_argument('--lr', type=float, default=3e-4)\n",
    "    ap.add_argument('--num_workers', type=int, default=4)\n",
    "    ap.add_argument('--fp16', action='store_true')\n",
    "    ap.add_argument('--save', type=str, default='runs/repvit_embed_512.pt')\n",
    "    ap.add_argument('--seed', type=int, default=42)\n",
    "    args = ap.parse_args()\n",
    "\n",
    "    set_seed(args.seed)\n",
    "    os.makedirs(os.path.dirname(args.save), exist_ok=True)\n",
    "    device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "    print(f\"Device: {device}\")\n",
    "\n",
    "    # 1) 复用你指定的 timm 模型\n",
    "    backbone = timm.create_model(args.model_name, pretrained=True).eval()\n",
    "    # 移除分类头 + 开池化\n",
    "    if hasattr(backbone, 'reset_classifier'):\n",
    "        backbone.reset_classifier(num_classes=0, global_pool='avg')\n",
    "\n",
    "    model = RepViTWithHead(backbone, embed_dim=args.embed_dim, mlp=args.mlp_head).to(device)\n",
    "\n",
    "    # 2) 冻结前面一部分参数\n",
    "    freeze_by_ratio(model.backbone, args.freeze_ratio)\n",
    "    # head 全部训练\n",
    "    for p in model.head.parameters():\n",
    "        p.requires_grad = True\n",
    "\n",
    "    # 3) 数据\n",
    "    tf_train = transforms.Compose([\n",
    "        transforms.Resize(args.image_size),\n",
    "        transforms.RandomResizedCrop(args.image_size, scale=(0.7,1.0)),\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "        transforms.ColorJitter(0.2,0.2,0.2,0.1),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize((0.485,0.456,0.406),(0.229,0.224,0.225)),\n",
    "    ])\n",
    "\n",
    "    if args.method == 'triplet':\n",
    "        tri_csv = os.path.join(args.csv_dir, 'triplets.csv')\n",
    "        ds = TripletDataset(tri_csv, tf_train)\n",
    "        dl = DataLoader(ds, batch_size=args.batch_size, shuffle=True,\n",
    "                        num_workers=args.num_workers, pin_memory=True, drop_last=True)\n",
    "        criterion = nn.TripletMarginLoss(margin=0.2, p=2.0)\n",
    "    else:\n",
    "        pos_csv = os.path.join(args.csv_dir, 'pairs_pos.csv')\n",
    "        neg_csv = os.path.join(args.csv_dir, 'pairs_neg.csv')\n",
    "        ds = PairDataset(pos_csv, neg_csv, tf_train)\n",
    "        dl = DataLoader(ds, batch_size=args.batch_size, shuffle=True,\n",
    "                        num_workers=args.num_workers, pin_memory=True, drop_last=True)\n",
    "        criterion = BCEPairLoss(scale=20.0)\n",
    "\n",
    "    # 4) 优化器\n",
    "    optim = torch.optim.AdamW(filter(lambda p: p.requires_grad, model.parameters()),\n",
    "                              lr=args.lr, weight_decay=1e-4)\n",
    "    scaler = torch.cuda.amp.GradScaler(enabled=args.fp16)\n",
    "\n",
    "    # 5) 训练\n",
    "    for ep in range(1, args.epochs+1):\n",
    "        model.train()\n",
    "        t0 = time.time(); loss_acc = 0.0\n",
    "        for it, batch in enumerate(dl):\n",
    "            optim.zero_grad(set_to_none=True)\n",
    "            with torch.cuda.amp.autocast(enabled=args.fp16):\n",
    "                if args.method == 'triplet':\n",
    "                    xa, xp, xn = [t.to(device) for t in batch]\n",
    "                    za, zp, zn = model(xa), model(xp), model(xn)\n",
    "                    loss = criterion(za, zp, zn)\n",
    "                else:\n",
    "                    xa, xb, y = batch\n",
    "                    xa, xb, y = xa.to(device), xb.to(device), y.to(device)\n",
    "                    za, zb = model(xa), model(xb)\n",
    "                    loss = criterion(za, zb, y)\n",
    "            scaler.scale(loss).backward()\n",
    "            scaler.step(optim); scaler.update()\n",
    "            loss_acc += loss.item()\n",
    "\n",
    "        dt = time.time()-t0\n",
    "        print(f\"[Epoch {ep}] loss={loss_acc/len(dl):.4f}  time={dt:.1f}s\")\n",
    "\n",
    "        # 轻量评测（组内最近邻召回）\n",
    "        test_csv = os.path.join(args.csv_dir, 'test.csv')\n",
    "        rec = eval_group_recall(model, test_csv, args.image_size, device)\n",
    "        if rec is not None:\n",
    "            print(f\"[Eval] group-NN recall@1 = {rec*100:.2f}%\")\n",
    "\n",
    "        torch.save({'epoch': ep, 'model': model.state_dict(), 'args': vars(args)}, args.save)\n",
    "        print(f\"[Saved] {args.save}\")\n",
    "\n",
    "    print(\"Done.\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
